# Руководство пользователя — Enterprise AI Assistant

Подробное описание работы с Web-интерфейсом: вход, чат, настройка моделей, загрузка документов, админка и рекомендации по использованию.

---

## 1. Вход и роли

### Вход в систему

- Открой в браузере `https://YOUR_DOMAIN` (или `https://IP`). Отобразится страница входа.
- Введи **логин** и **пароль**, выданные администратором.
- После успешной аутентификации сохраняется **JWT-токен**; сессия действует в течение времени, заданного в настройках (по умолчанию 24 часа).

### Роли

| Роль   | Возможности |
|--------|-------------|
| **user** | Чат, загрузка файлов, просмотр статуса, просмотр списка моделей и назначений. Не может менять настройки, ключи провайдеров и управление контейнерами. |
| **admin** | Всё то же, что и user, плюс: **Настройки** (`/settings`), **Модели** — сохранение API-ключей облачных провайдеров, **Админка** (`/admin`), **Пользователи** (`/users`). |

Доступ к страницам **Настройки**, **Админка** и **Пользователи** возможен только с ролью `admin`.

---

## 2. Чат (`/chat`)

### Назначение

Чат — основной интерфейс для вопросов к производственным данным на естественном языке. Ответ формирует **LLM** (большая языковая модель), которая сама решает, какие инструменты вызвать: поиск по графу, по документам, по складу или анализ чертежа.

### Как задавать вопросы

- Вводи вопрос в поле ввода и нажми **Отправить** (или Enter).
- Ответ приходит **потоком** (SSE): текст появляется по мере генерации.
- В интерфейсе отображаются вызовы инструментов (например, `docs_search`, `inventory_sql_search`), если модель к ним обратилась.

### Примеры запросов

| Вопрос | Ожидаемое поведение |
|--------|---------------------|
| «Сколько PA6-GF30 на складе?» | Вызов `inventory_sql_search` → Text-to-SQL по каталогам/складу. |
| «Покажи все ТПА и их оснастку» | Вызов `graph_search` → запрос к графу Neo4j. |
| «Трудозатраты по техпроцессу ТП-001» | Вызов `enterprise_graph_search` → Cypher с суммами времени по операциям (setup_time_min, machine_time_min). |
| «Трудоёмкость детали по чертежу 123-456» | Вызов `enterprise_graph_search` → суммарное время по техпроцессу детали. |
| «Как нарезать дюймовую резьбу на 16К20?» | Вызов `docs_search` → семантический поиск по документам в Qdrant. |
| «Что на чертеже в файле X?» | Вызов `blueprint_vision` → анализ изображения через VLM. |
| «Проверь чертёж 123-456 на нормоконтроль» | Вызов `norm_control` → отчёт о соответствии ГОСТам (passed/checks/summary). |
| «Проверь техпроцесс ТП-001 на нормы» | Вызов `norm_control` → отчёт нормоконтроля техпроцесса. |

### Агентный цикл

Модель может вызывать несколько инструментов подряд (до лимита итераций, заданного в настройках, по умолчанию 5). Например: сначала поиск по документам, затем уточняющий запрос к складу. Итоговый ответ объединяет результаты.

### Сессии

- В боковой панели отображаются **сессии чата**. Можно создавать новый чат или переключаться между существующими.
- История сообщений хранится в рамках сессии в базе данных.

---

## 3. Загрузка документов (`/upload`)

### Назначение

Страница предназначена для загрузки файлов в каталоги проекта. После загрузки файлы должны быть **проиндексированы** (ETL), чтобы они участвовали в поиске по документам и, при необходимости, в графе и складе.

### Куда загружать

Рекомендуемая структура (соответствует папкам в `documents/`):

| Папка | Назначение |
|-------|------------|
| **blueprints/** | Чертежи (PNG, JPEG) — анализ через VLM, индексация в Neo4j и Qdrant. |
| **manuals/** | Паспорта станков, инструкции (PDF, DOCX) → Qdrant. |
| **gosts/** | ГОСТы (PDF) → Qdrant. |
| **catalogs/** | Каталоги инструмента, металлов, полимеров (Excel) → PostgreSQL (склад). |
| **tech_processes/** | Техпроцессы (Excel) → Neo4j. |
| **emails/** | Деловая переписка (.eml) → Qdrant. |

Загрузка через Web UI помещает файлы в соответствующие директории на сервере. Дальнейшая индексация выполняется через **Админку** (запуск ETL-задач) или из командной строки (`make ingest-all` и др.).

---

## 4. Модели (`/models`)

Страница разделена на вкладки **Локальные** и **Облачные**, а также блок **Назначение по ролям**.

### 4.1 Локальные модели

Локальные модели обрабатывают данные на вашем сервере и не отправляют их во внешние API.

- **Ollama GPU** — LLM и VLM (например, Qwen3:30b, Qwen3-VL:14b). Показывается список уже загруженных моделей.
- **Ollama CPU** — модели для embedding и reranker (например, qwen3-embedding, qwen3-reranker). Аналогично отображается список моделей.
- **vLLM** — локальный OpenAI-совместимый сервер. Если сервис vLLM настроен и доступен, здесь отображаются его модели.

**Загрузка моделей Ollama:** в блоке «Загрузить модель Ollama» укажи имя модели (например, `qwen3:30b`) и нажми **Загрузить**. Процесс может занять время и требует прав администратора (вызов идёт через API к контейнеру Ollama).

**Путь к данным Ollama:** по умолчанию данные хранятся в `/home/ollama-models` (подпапки `gpu` и `cpu`). Это задаётся в **Настройках** и переменной окружения `OLLAMA_MODELS_PATH` в `.env`. После удаления проекта модели остаются на хосте и не требуют повторной загрузки.

### 4.2 Облачные модели

Облачные провайдеры позволяют использовать внешние API (данные покидают периметр предприятия).

Поддерживаемые провайдеры:

- **OpenAI**
- **Anthropic (Claude)**
- **OpenRouter**
- **Minimax**
- **Z.ai**

Для каждого облачного провайдера:

- Отображается, задан ли **API-ключ** (да/нет).
- Администратор может ввести или заменить ключ в соответствующем поле и нажать **Сохранить ключ**. Ключи хранятся в БД в зашифрованном виде.
- Список моделей подтягивается с сервера провайдера (если API доступен и ключ задан).

**Важно:** использование облачных моделей для обработки документов может приводить к передаче данных третьим лицам. Для конфиденциальных данных рекомендуется использовать локальные модели (Ollama, vLLM).

### 4.3 Назначение по ролям

Внизу страницы **Назначение по ролям** задаётся, какая модель какого провайдера используется для каждой роли:

| Роль | Описание |
|------|----------|
| **LLM** | Чат, генерация ответов, выбор инструментов. |
| **VLM** | Анализ чертежей (изображений). |
| **Embedding** | Векторизация текста для семантического поиска по документам. |
| **Reranker** | Переранжирование результатов поиска. |

В выпадающем списке для каждой роли выбирается пара **провайдер + модель** (например, «Ollama GPU: qwen3:30b»). После выбора назначение сохраняется автоматически. Если для роли выбрана облачная модель, отображается предупреждение (иконка).

---

## 5. Настройки (`/settings`)

Доступны только пользователям с ролью **admin**. Значения, сохранённые здесь, имеют приоритет над переменными окружения из `.env` (кроме паролей БД и JWT — они задаются только в `.env`).

### 5.1 Модели (Ollama)

- **LLM модель**, **VLM модель**, **Embedding модель**, **Reranker модель** — имена моделей в Ollama (должны совпадать с именами при `ollama pull`).

### 5.2 Ollama URL и путь к данным моделей

- **Ollama GPU URL**, **Ollama CPU URL** — адреса контейнеров Ollama (по умолчанию `http://ollama-gpu:11434` и `http://ollama-cpu:11434`).
- **Путь к данным моделей Ollama (на хосте)** — каталог на хосте, где хранятся данные Ollama. По умолчанию `/home/ollama-models`. Для применения на Docker нужно задать в `.env` переменную `OLLAMA_MODELS_PATH` и перезапустить контейнеры (`docker compose up -d`).

### 5.3 Контекст и таймауты

- Размер контекста для LLM и VLM (например, 16384).
- Таймауты (в секундах) для LLM, VLM, Embedding, Reranker и переключения моделей в VRAM.

### 5.4 Qdrant

- Имя коллекции, размерность вектора, имена dense/sparse векторов, лимиты prefetch и финального количества результатов.

### 5.5 Чат и агент

- **Макс. итераций инструментов** — сколько раз подряд модель может вызывать инструменты в одном раунде чата.

### 5.6 Облачные провайдеры

- **Облачный LLM таймаут**, **Облачный Embedding таймаут** — таймауты для вызовов облачных API.
- **OpenRouter Base URL** — базовый URL OpenRouter (по умолчанию `https://openrouter.ai/api/v1`).
- **vLLM Base URL** — URL локального vLLM (например, `http://vllm:8000/v1`). Если пусто, vLLM не используется.

### 5.7 OpenClaw (Telegram-агент)

- **Модель LLM для OpenClaw** — какая модель используется в Telegram-боте (по умолчанию совпадает с основной LLM моделью).
- **Автообновление OpenClaw при рестарте** — при включении при каждом рестарте контейнера выполняется `npm install -g openclaw@latest`.

### 5.8 Прочее

- **Директория документов** — базовый путь к загружаемым документам.
- **CORS origins** — разрешённые источники для фронтенда (через запятую; в production обычно домен сервера).

После изменений нажми **Сохранить настройки**. Часть параметров применяется сразу; для применения пути Ollama и переменных окружения требуется перезапуск контейнеров и задание `OLLAMA_MODELS_PATH` в `.env`.

---

## 6. Статус (`/status`)

Страница отображает состояние сервисов:

- Доступность API, Ollama GPU/CPU, Qdrant, Neo4j и др.
- Информация о загруженных моделях и использовании VRAM (где применимо).

Используется для быстрой проверки готовности системы к работе и диагностики.

---

## 7. Админка (`/admin`)

Доступна только **admin**. Позволяет управлять инфраструктурой без выхода на сервер по SSH.

### 7.1 Контейнеры

- Список контейнеров проекта с индикацией состояния (работает/остановлен).
- Для каждого контейнера доступны действия: **запуск**, **остановка**, **перезапуск** (в зависимости от текущего состояния).

### 7.2 Логи

- Выбор контейнера и просмотр **live-логов** (поток в реальном времени). Удобно для отладки и мониторинга.

### 7.3 Загрузка моделей Ollama

- Интерфейс для запуска загрузки моделей Ollama (аналог `ollama pull`) с отображением прогресса. Используется, если не пользуешься блоком на странице **Модели**.

### 7.4 ETL / Индексация

- Запуск задач индексации данных:
  - Excel → PostgreSQL (каталоги, склад).
  - PDF/DOCX → Qdrant (документы).
  - Чертежи → VLM → Neo4j + Qdrant.
  - Техпроцессы → Neo4j и т.д.

После загрузки новых файлов в `documents/` необходимо запустить соответствующие ETL-задачи, чтобы данные попали в поиск и граф.

---

## 8. Пользователи (`/users`)

Доступна только **admin**. Список пользователей системы с возможностью:

- Создания новых пользователей (логин, пароль, роль).
- Изменения роли (user/admin).
- Сброса пароля.

Удаление пользователей (если реализовано в API) также выполняется отсюда.

---

## 9. Индексация данных (ETL)

Чтобы загруженные документы участвовали в поиске и в графе:

1. Размести файлы в нужных папках (через **Загрузка** или напрямую в `documents/` на сервере).
2. Запусти индексацию:
   - через **Админку** — кнопки запуска соответствующих ETL-задач;
   - или из командной строки: `make ingest-all` (все пайплайны), либо отдельно `make ingest-excel`, `make ingest-pdf`, `make ingest-blueprints`, `make ingest-techprocess`.

Структура каталогов и назначение папок описаны в разделе **Загрузка документов** выше и в [README](../README.md#структура-документов).

---

## 10. Рекомендации по безопасности и использованию

- **Пароли и JWT:** задавай надёжные пароли и храни `JWT_SECRET_KEY` и пароли БД только в `.env`; не коммить `.env` в репозиторий.
- **HTTPS:** в production используй домен с действительным сертификатом (Let's Encrypt через Caddy).
- **Конфиденциальные данные:** для обработки внутренних документов предпочтительны локальные модели (Ollama, vLLM). Облачные провайдеры используй только при понимании рисков передачи данных.
- **API-ключи облачных провайдеров:** вводятся только в Web UI (админка → Модели → Облачные) и хранятся в БД в зашифрованном виде.
- **Резервное копирование:** регулярно делай бэкапы PostgreSQL и при необходимости Neo4j, Qdrant; каталог `documents/` и при необходимости `/home/ollama-models` также стоит включать в стратегию бэкапов.
- **Обновления:** после обновления кода пересобери образы и перезапусти контейнеры (`make update` или `docker compose build && docker compose up -d`). Перед этим проверь [README](../README.md) и список изменений.

---

## Связанные документы

- [README](../README.md) — обзор проекта, быстрый старт, структура, Makefile.
- [INSTALL_AUDIT.md](INSTALL_AUDIT.md) — аудит установки через `install.sh`.
- [OPENCLAW_AUDIT.md](OPENCLAW_AUDIT.md) — настройка и аудит Telegram-агента OpenClaw.
