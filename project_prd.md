# Product Requirements Document (PRD): Enterprise AI Assistant & Knowledge Graph

## 1. Описание проекта (Project Overview)
**Цель:** Разработать масштабируемую локальную ИИ-систему для автоматизации рутинных задач ИТР на среднем производственном предприятии. Система должна выступать единым интеллектуальным интерфейсом ко всем знаниям завода.
**Охват:** Работает с документацией для ЧПУ, универсальных токарных и фрезерных станков, термопластавтоматов (ТПА) и сборочных линий.
**Функционал:** Семантический поиск, анализ чертежей (Vision), понимание сложных связей (Деталь -> Оснастка/Пресс-форма -> Станок -> Инструмент -> Материал), выявление несоответствий в техпроцессах, автономное выполнение действий (написание писем, запросы в ERP/склад).
**Оркестратор:** В качестве ядра агента и системы интеграции с мессенджерами используется open-source фреймворк **OpenClaw**.

## 2. Аппаратное обеспечение и ограничения (Hardware Constraints)
*   **CPU:** AMD Ryzen 9 9900X (высокая производительность для БД, эмбеддингов и Reranker).
*   **RAM:** 64GB DDR5 (cl28 6000).
*   **GPU:** 1x NVIDIA RTX 3090 (24GB VRAM).
*   **Storage:** 2TB SSD (БД, кэш) + 12TB HDD (Архив документов).
*   **Ограничение (Критично!):** 24GB VRAM требует строгого управления памятью. LLM и VLM должны работать через vLLM или Ollama с использованием квантования (AWQ/GGUF 4-bit) или настроенной динамической выгрузкой моделей из GPU в RAM при смене задач. Модели Embedding и Reranker работают преимущественно на CPU. Полностью оффлайн контур (Air-gapped).

## 3. Модели (AI Models)
*   **LLM (Main Reasoning, Routing, Tool Use):** `qwen3:30b`
*   **VLM (Vision, Blueprint & Scheme parsing):** `qwen3-vl:14b`
*   **Embeddings:** `qwen3-embedding`
*   **Reranker:** `qwen3-reranker`

## 4. Архитектура системы (System Architecture)
Система строится на базе **Docker Compose**:
1.  **AI Engine:** Ollama / vLLM.
2.  **Vector DB (Qdrant):** Хранение текстовых чанков (инструкции к станкам, письма, текстовые описания техпроцессов, ГОСТы). Обязателен Hybrid Search (BM25 + Dense Vectors).
3.  **Graph DB (Neo4j):** Ядро логики. Узлы: `Деталь`, `Сборка`, `Чертеж`, `Материал`, `Станок` (ЧПУ/Универсал/ТПА), `Пресс-форма/Оснастка`, `Инструмент`, `Техпроцесс`. Связи: `ПРОИЗВОДИТСЯ_НА`, `ИСПОЛЬЗУЕТ_ИНСТРУМЕНТ`, `СОСТОИТ_ИЗ` и т.д.
4.  **Relational DB (PostgreSQL):** Складские остатки, номенклатура (каталоги фрез, резцов, полимеров), справочники сотрудников.
5.  **Agent Orchestrator:** **OpenClaw** (в Docker). Подключается к мессенджерам (Telegram/локальный чат) и управляет скиллами.

## 5. Пайплайн загрузки данных (Data Ingestion / ETL)
Необходимо разработать масштабируемые скрипты парсинга:
*   **Структурированные данные (Excel/CSV):** Справочники инструмента и материалов -> *PostgreSQL*.
*   **Неструктурированные тексты (PDF, Word, EML):** Руководства по эксплуатации станков, ГОСТы, письма -> Чанкинг -> Эмбеддинги -> *Qdrant*.
*   **Чертежи (PDF, PNG):** Прогон через `qwen3-vl:14b` (системный промпт: извлечь деталь, допуски, материал, шероховатости) -> *Метаданные в Neo4j + Текст в Qdrant*.
*   **Техпроцессы и УП:** Парсинг связей (какая деталь, на каком оборудовании, с какой оснасткой) -> *Формирование графа в Neo4j*.

## 6. Логика Агента (OpenClaw Skills System)
Вся интеграция с локальными базами оформляется как **навыки (Skills) для OpenClaw**. Директория: `workspace/skills/`.
Каждый навык состоит из файла конфигурации (`SKILL.md` / `config.yaml`) и Python-скрипта.

Разрабатываемые кастомные навыки:
1.  **`enterprise-graph-search`**: Text-to-Cypher. Принимает вопрос, генерирует запрос к Neo4j. *Пример: "Покажи весь маршрут изготовления детали Х и нужную оснастку".*
2.  **`enterprise-docs-search`**: Hybrid Search + Reranking по Qdrant. Ищет абзацы в инструкциях, паспортах станков, ГОСТах.
3.  **`blueprint-vision`**: Принимает путь к изображению, отправляет в VLM (`qwen3-vl`), возвращает текстовое описание технических требований чертежа.
4.  **`inventory-sql-search`**: Text-to-SQL. Ищет наличие полимеров, металла или инструмента на складе (PostgreSQL).

*(Отправка писем, создание задач в таск-трекере и работа с календарем будет осуществляться через стандартные навыки из ClawHub, код для них писать не нужно).*

## 7. Этапы разработки (Phases of Implementation)
*   **Phase 1: Infrastructure & DBs.** Настройка `docker-compose.yml` (Qdrant, Neo4j, PostgreSQL, OpenClaw). Инициализация схем баз данных. Настройка `.env`.
*   **Phase 2: AI Engine Wrapper.** Написание базовых Python-классов для общения с локальными Qwen3 (LLM, VLM, Embeddings) через API Ollama/vLLM. Управление промптами.
*   **Phase 3: ETL Pipelines.** Разработка скриптов в `src/ingestion/` для заполнения всех трех баз (Graph, Vector, SQL) тестовыми данными предприятия.
*   **Phase 4: OpenClaw Skills.** Обертывание логики поиска по базам в формат навыков OpenClaw. Написание строгих инструкций в `SKILL.md` для каждого навыка, чтобы Qwen3:30b безошибочно понимал, когда их вызывать.
*   **Phase 5: Testing & Prompt Engineering.** Тестирование комплексных запросов через интерфейс OpenClaw. Борьба с галлюцинациями.

## 8. Примеры сценариев для тестирования (Use Cases)
1.  **Сценарий "Термопластавтомат":** Пользователь пишет: *"У нас заказ на 5000 пластиковых втулок по чертежу №123. Какая пресс-форма нужна и свободен ли подходящий ТПА?"* Агент через `blueprint-vision` понимает чертеж, через `enterprise-graph-search` находит пресс-форму, проверяет ее применимость к станкам ТПА, через `inventory-sql-search` проверяет наличие нужного объема полиамида на складе. Выдает сводный отчет.
2.  **Сценарий "Универсальный станок":** *"Как настроить гитару токарно-винторезного 16К20 для нарезки дюймовой резьбы?"* Агент использует `enterprise-docs-search`, находит нужный скан паспорта станка в Qdrant и выдает точную инструкцию.

## 9. Требования к коду
*   Язык: Python 3.11+.
*   Абсолютная модульность. Код навыков должен быть изолирован от ETL-скриптов.
*   Использовать `Pydantic` для валидации данных при Text-to-SQL и Text-to-Cypher генерации.
*   Асинхронность (`asyncio`, `Aiohttp`) при обращении к базам и API моделей для ускорения работы.